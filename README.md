
# Handpose Sound Demo

このリポジトリは、ブラウザ上でカメラ映像から手のランドマークを検出し、手の開き具合と横位置に応じて
連続的に音の高さ（周波数）を制御するデモです。

---

## 仕様（厳密）

- 入力:
  - ユーザーのウェブカメラ映像（WebRTC getUserMedia を通じて取得）。
  - ユーザーによる「Start Audio」ボタンのクリック（ブラウザのオーディオ再生ポリシーに従う）。

- 出力:
  - ブラウザ上のキャンバスにカメラ映像と検出された手のランドマークを描画。
  - 単一の正弦波オシレータ（Web Audio API）による音声出力（モノラル）。

- 動作:
  - ml5.js の Handpose（TensorFlow.js ベース）を使用して手の 21 点ランドマークを検出する。
  - 親指先（landmark index 4）と小指先（index 20）の 2 点間距離 d を計算する。
  - d を事前定義された最小・最大距離範囲 [MIN_D, MAX_D] にクランプし、リニアに周波数にマップする：
    - d = MIN_D -> 周波数 = LOW_FREQ
    - d = MAX_D -> 周波数 = HIGH_FREQ
  - 手の全ランドマークの重心 x 座標（キャンバス座標）を計算し、その横位置に基づいて周波数に小さな乗算（ピッチベンド）を適用する。
  - 周波数は AudioContext のスムーズなスケジュール（linearRampToValueAtTime）で更新されるため、連続的で滑らかなピッチ変化が得られる。
  - 手が検出されない場合はゲインをフェードアウトして無音状態にする。

---

## ファイル一覧（何をしているか）

- `index.html`
  - ページのエントリポイント。外部ライブラリ（p5.js, ml5.js）を読み込み、アプリモジュール
    (`config.js`, `audioEngine.js`, `handposeModel.js`, `drawUtils.js`, `sketch.js`) を順に読み込みます。
  - 画面上に「Start Audio」ボタンを配置し、ユーザー操作で AudioContext の開始をトリガーします。

- `sketch.js`
  - p5.js のセットアップとメインループを管理する“司令塔”。
  - カメラキャプチャの生成、キャンバスのリサイズ処理、handpose の予測結果受け取り（コールバック）を行います。
  - 受け取ったランドマークから距離・重心などを計算し、`audioEngine` と `drawUtils` にデータを渡して描画・音声制御を行います。

- `config.js`
  - アプリ全体で使う定数（MIN_D / MAX_D / LOW_FREQ / HIGH_FREQ / BEND_RANGE / グラフ設定など）を一元管理し、
    `window.CONFIG` として公開します。

- `audioEngine.js`
  - Web Audio API を使った単純な単音シンセの管理（オシレータ生成、Gain 管理、周波数のスムーズな更新、
    フェードイン/フェードアウト）を行います。
  - `window.audioEngine` として API（ensureStarted, rampToFrequency, noteOn, noteOff など）を提供します。

- `handposeModel.js`
  - ml5.handpose の初期化と予測イベントの登録を行うラッパーです。
  - `window.handposeCtrl.init(video, onPredict)` でモデルを初期化し、予測コールバックを登録します。

- `drawUtils.js`
  - 手のランドマーク描画（キーポイント＋接続線）と周波数グラフ描画のロジックを切り出したユーティリティ群。
  - p5 の描画関数内から `window.drawUtils.drawHand(...)` / `drawFrequencyGraph(...)` を呼んで使います。

- `soundA.mp3`, `soundB.mp3`（もし使う場合）
  - 現状の実装では使用していませんが、将来的なサンプル音源や効果音として配置されています。

- `README.md`
  - このファイル。プロジェクトの目的、実行手順、パラメータや注意点を記載しています。

---

## 必要条件（実行環境）

- ブラウザ：最新の Chrome、Firefox、Edge、あるいは Safari のいずれか（WebRTC と Web Audio API をサポートしていること）。
  - 注意: 一部ブラウザや古いバージョンでは期待通りに動作しない場合があります。
- ローカルでの実行は HTTP サーバを使用してください（`file://` で直接開くとカメラやオーディオの権限・ワークレットの制限で正しく動作しないことがあります）。
- ネットワーク接続：ml5.js は CDN から読み込まれるため、初回読み込み時にインターネット接続が必要です。

---

## 実行手順（正確）

1. ターミナルを開き、プロジェクトのルートディレクトリに移動します。例:

```bash
cd /Users/watanabekeiyu/Documents/駒場祭/Code
```

2. 簡易 HTTP サーバを起動します（Python 3 を想定）:

```bash
python3 -m http.server 8000
```

3. ブラウザで次の URL を開きます:

```
http://localhost:8000
```

4. ページが表示されたら、必ず最初に「Start Audio」ボタンをクリックします。
   - これによりブラウザの AudioContext が `resume()` され、オシレータの音が出せるようになります。
   - ブラウザがカメラ使用の許可を求めるので「許可」してください。

5. カメラ映像がキャンバスに表示され、手が検出されると緑のランドマークが表示されます。親指と小指を開閉して音の高さを確認してください。手を左右に動かすと微小なピッチベンドがかかります。

---

## 主要パラメータ（`config.js` / `sketch.js` 内の変数）

- MIN_D (数値): 判定に使用する距離の下限。デフォルト: 20
- MAX_D (数値): 判定に使用する距離の上限。デフォルト: 300
- LOW_FREQ (Hz): 指を閉じたときに対応する最小周波数。デフォルト: 150
- HIGH_FREQ (Hz): 指を開いたときに対応する最大周波数。デフォルト: 900
- BEND_RANGE (比率): 手の横位置によるピッチ変動の上限（±比率）。デフォルト: 0.06（±6%）
- gain の目標値: 手が検出されたときの最大ボリューム（`audioEngine.noteOn` のデフォルト引数等で設定）。

これらの値は `config.js` や `sketch.js` 内で直接変更できます。視覚的な位置や手のサイズ、カメラとの距離によって最適値が変わるため、実機で確認しながら調整してください。

---

## 安全で確実な動作のための注意点（トラブルシューティング）

- 音が鳴らない／Start ボタンを押しても無反応:
  - ブラウザのコンソールにエラーが出ていないか確認してください。
  - `http://localhost:8000` のように HTTP サーバ経由で開いているか確認（`file://` ではないこと）。
  - ブラウザがカメラのアクセスをブロックしていないか確認。

- コンソールに "Unable to load a worklet's module" などのエラーが出る場合:
  - 以前の実装で `p5.sound` を使っていると発生する可能性があります。本プロジェクトはネイティブ WebAudio を使用しているため、`p5.sound` の読み込みが無いことを確認してください。

- 手が検出されない／ランドマークがずれる:
  - 照明を明るくする、背景をシンプルにする、カメラに手を近づける／遠ざけるなどで改善します。
  - `MIN_D` と `MAX_D` を調整して、指距離のスケールをカメラ距離に合わせてください。

---

## 変更履歴（短く）

- v1.0: ml5.handpose を用いた手検出と、ネイティブ WebAudio による連続ピッチ制御を実装。

---

## ライセンス

- このリポジトリのコードは特にライセンス指定がない限り自由に参照・改変できます。公開配布や商用利用を行う場合は、使用ライブラリ（p5.js, ml5.js 等）のライセンス条項を確認してください。

---

疑問点や改善したい点があれば具体的に指示をください。README の文言をさらに厳密にすることも可能です。
